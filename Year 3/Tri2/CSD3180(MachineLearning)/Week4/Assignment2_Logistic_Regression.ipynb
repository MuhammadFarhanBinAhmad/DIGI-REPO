{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Assignment2_Logistic_Regression.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS385/CSD3185/CSD3186: Assignment 2 Logistic Regression\n",
    "\n",
    "## Deliverables\n",
    "Your submission for this assignment should be __ONE__ file - a zip file generated by the `grader.export(_)` function down below under 'Submission'. This function will auto create the zip file which contains this particular completed notebook file for you.  \n",
    "\n",
    "Subsequently, rename your zip file like this: __coursecode_A2_your_full_name.zip__  \n",
    "Eg. CS385_A2_john_doe.zip  \n",
    "\n",
    "To complete this assignment, you should follow instructions in Section Tasks.\n",
    "\n",
    "## IMPORTANT! READ THIS BEFORE STARTING...\n",
    "- DO NOT delete existing cells, but you can add more cells in between.\n",
    "- DO NOT modify the content of the existing cells unless otherwise stated.\n",
    "- Run the cell with `grader.check(_)` to check your solutions whenever you have completed each tasks.\n",
    "- Follow the file naming convention for the zip file as spelled out above strictly.\n",
    "- DO NOT rename this notebook file. It shall be 'Assignment2_Logistic_Regression.ipynb'. \n",
    "\n",
    "Please adhere strictly to the instructions as stated above as failure to do so might result in deduction of marks by the autograder.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics Covered\n",
    "**Logistic Regression** is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable takes on one of two possible values, typically coded as 1 (e.g., yes, success, etc.) or 0 (e.g., no, failure, etc.). The logistic regression model estimates the probability of the dependent variable being 1, denoted as $P(Y=1)$, based on the input features ($X$).\n",
    "\n",
    "In this notebook, We'll use the <a href=\"https://archive.ics.uci.edu/dataset/222/bank+marketing\">Bank Marketing dataset</a> from the UCI Machine Learning Repository, which focuses on direct marketing campaigns conducted via phone calls by a Portuguese banking institution. The objective is to predict whether a client will subscribe to a term deposit (coded as 1 for yes or 0 for no).\n",
    "\n",
    "**Notebook Structure**:\n",
    "1. Loading and Inspecting the Dataset [_5 marks_]\n",
    "2. Exploring the Dataset (Part I) [_5 marks_]\n",
    "3. Exploring the Dataset (part II) [_15 marks_]\n",
    "4. Create Dummy variables \n",
    "5. Random Over-sampling of the Minority Class [_25 marks_]\n",
    "6. Logistic Regression Model Fitting [_20 marks_]\n",
    "7. Grid Searching for Hyperparameter Selection [_30 marks_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Overview**   \n",
    "|**Variable**     |**Description**                         |**Type**                                     |\n",
    "|:-----------------------|:-------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------|\n",
    "| `age`                | Age                                                                                                                     | Numeric                                                                                   |\n",
    "| `job`                | Type of job                                                                                                             | Categorical: “admin”, “blue-collar”, “entrepreneur”, “housemaid”, “management”, “retired”, “self-employed”, “services”, “student”, “technician”, “unemployed”, “unknown” |\n",
    "| `marital`            | Marital status                                                                                                          | Categorical: “divorced”, “married”, “single”, “unknown”                                   |\n",
    "| `education`          | Education level                                                                                                         | Categorical: “basic.4y”, “basic.6y”, “basic.9y”, “high.school”, “illiterate”, “professional.course”, “university.degree”, “unknown” |\n",
    "| `default`            | Has credit in default?                                                                                                  | Categorical: “no”, “yes”, “unknown”                                                      |\n",
    "| `housing`            | Has housing loan?                                                                                                       | Categorical: “no”, “yes”, “unknown”                                                      |\n",
    "| `loan`               | Has personal loan?                                                                                                      | Categorical: “no”, “yes”, “unknown”                                                      |\n",
    "| `contact`            | Contact communication type                                                                                              | Categorical: “cellular”, “telephone”                                                     |\n",
    "| `month`              | Last contact month of year                                                                                              | Categorical: “jan”, “feb”, “mar”, …, “nov”, “dec”                                        |\n",
    "| `day_of_week`        | Last contact day of the week                                                                                            | Categorical: “mon”, “tue”, “wed”, “thu”, “fri”                                           |\n",
    "| `duration`           | Last contact duration in seconds. Note: affects the output target and should be discarded for realistic models.          | Numeric                                                                                   |\n",
    "| `campaign`           | Number of contacts performed during this campaign for this client                                                       | Numeric                                                                                   |\n",
    "| `pdays`              | Number of days since last contact from a previous campaign (999 = not previously contacted)                             | Numeric                                                                                   |\n",
    "| `previous`           | Number of contacts performed before this campaign for this client                                                       | Numeric                                                                                   |\n",
    "| `poutcome`           | Outcome of the previous marketing campaign                                                                              | Categorical: “failure”, “nonexistent”, “success”                                         |\n",
    "| `emp.var.rate`       | Employment variation rate                                                                                               | Numeric                                                                                   |\n",
    "| `cons.price.idx`     | Consumer price index                                                                                                   | Numeric                                                                                   |\n",
    "| `cons.conf.idx`      | Consumer confidence index                                                                                              | Numeric                                                                                   |\n",
    "| `euribor3m`          | Euribor 3-month rate                                                                                                   | Numeric                                                                                   |\n",
    "| `nr.employed`        | Number of employees                                                                                                    | Numeric                                                                                   |\n",
    "| **Target variable**  | **Description**                                                                                                         | **Type**                                                                                  |\n",
    "| `y`                  | Has the client subscribed to a term deposit?                                                                           | Binary: “1” (Yes), “0” (No)                                                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provides the bank customers’ information. It includes 41,188 records and 21 fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** To ensure the grid search section in Part 7 runs without errors, please upgrade your scikit-learn package to version 1.6.1. You only need to run the following command once. After successfully upgrading, you can comment out the line to avoid reinstallation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user --upgrade scikit-learn==1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "#plt.rc(\"font\", size=14)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "#sns.set(style=\"white\")\n",
    "#sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Inspecting the Dataset\n",
    "\n",
    "In this section, we will load the dataset into a pandas DataFrame and perform a quick inspection. This step ensures the data is properly loaded and gives an initial understanding of its structure.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Load the dataset <code>\"banking.csv\"</code> into a pandas DataFrame called <code>data</code>. \n",
    "- Display the first 5 rows of <code>data</code> using the <code>head()</code> method.\n",
    "- Provide summary statistics for numeric columns in the DataFrame using the `describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Load dataset\n",
    "data = ...\n",
    "\n",
    "# Display the first 5 rows\n",
    "head_data = ...\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(head_data)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Provide summary statisitcis for numberical columns in the dataframe\n",
    "print(\"Summary statistics for numerical columns:\")\n",
    "data_description = ...\n",
    "print(data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Dataset (part i)\n",
    "In this section, we will explore the dataset further to identify missing values, understand categorical variables, and examine the structure of the data. This step helps in identifying potential issues and gaining insights into the dataset.\n",
    "\n",
    "### Instructions\n",
    "- **Identify Missing Values**: Use an appropriate pandas method to calculate and display the number of missing values in each column.\n",
    "- **Understand Dataset Structure**: Verify the dataset's shape by printing the number of rows and columns.\n",
    "- **Check Unique Categories**: Display the unique categories in the `education` column to understand its categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Inspect the number of missing values in each column\n",
    "missing_values = ...\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Shape of the dataframe\n",
    "data_shape = ...\n",
    "print(\"\\nShape of the DataFrame:\")\n",
    "print(data_shape)\n",
    "\n",
    "# Check how many categories are in the education column\n",
    "education_categories = ...\n",
    "print(\"\\nUnique categories in the 'education' column:\")\n",
    "print(education_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The education column of the dataset has many categories and we need to reduce the categories for a better modelling. Let us group “basic.4y”, “basic.9y” and “basic.6y” together and call them “basic”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['education']=np.where(data['education'] =='basic.9y', 'Basic', data['education'])\n",
    "data['education']=np.where(data['education'] =='basic.6y', 'Basic', data['education'])\n",
    "data['education']=np.where(data['education'] =='basic.4y', 'Basic', data['education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After grouping, it reduced to six education categories: 'Basic', 'unknown', 'university.degree', 'high.school','professional.course', 'illiterate'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring the Dataset (part ii)\n",
    "In this section, we will analyze the target variable y to understand its distribution and derive some basic insights. This analysis helps assess class imbalance and potential relationships between the target and other variables.\n",
    "\n",
    "## Instructions\n",
    "- Display the value counts of the target variable y using the `value_counts()` method\n",
    "- Calculate the number and percentage of rows where y is 0 (no subscription) and 1 (subscription).\n",
    "- Display the mean of numeric columns grouped by the target variable y using the `groupby()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a count plot for the target variable\n",
    "sns.countplot(x='y', data=data, palette='hls')  \n",
    "plt.title(\"Count Plot for Target Variable 'y'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Display value counts for the target variable\n",
    "y_value_counts = ...\n",
    "print(\"Value counts for the target variable 'y':\")\n",
    "print(y_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Calculate subscription statistics\n",
    "count_no_sub = ...\n",
    "count_sub = ...\n",
    "\n",
    "pct_of_no_sub = ...\n",
    "pct_of_sub = ...\n",
    "\n",
    "print(f\"Percentage of no subscription: {pct_of_no_sub * 100:.2f}%\")\n",
    "print(f\"Percentage of subscription: {pct_of_sub * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Display the mean of numeric columns grouped by the target variable\n",
    "grouped_means = ...\n",
    "print(\"\\nMean of numeric columns grouped by 'y':\")\n",
    "print(grouped_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the outputs above, what are some observations? Please share some of your findings.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**  \n",
    "- Our classes are imbalanced, and the ratio of no-subscription to subscription instances is 89:11.\n",
    "- The average age of customers who bought the term deposit is higher than that of the customers who didn’t.  \n",
    "- The pdays (days since the customer was last contacted) is understandably lower for the customers who bought it. The lower the pdays, the better the memory of the last call and hence the better chances of a sale.  \n",
    "- Surprisingly, campaigns (number of contacts or calls made during the current campaign) are lower for customers who bought the term deposit.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. **Create dummy variables**  \n",
    "In this section, we will learn how to transform categorical variables into dummy variables, which are binary representations. **The codes in this section are provided and no modification is required.** Dummy variables are essential for preparing data for machine learning models that require numeric input.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'color': ['red', 'blue', 'green', 'red', 'green']\n",
    "})\n",
    "\n",
    "# Create dummy variables\n",
    "dummy_df = pd.get_dummies(data['color'], prefix='color')\n",
    "\n",
    "print(dummy_df)\n",
    "\n",
    "```\n",
    "**Output:**\n",
    "```\n",
    "   color_blue  color_green  color_red\n",
    "0       False        False       True\n",
    "1        True        False      False\n",
    "2       False         True      False\n",
    "3       False        False       True\n",
    "4       False         True      False\n",
    "```\n",
    "**Explanation:**\n",
    "* pd.get_dummies() takes the color column and creates a binary column for each unique category (blue, green, red).\n",
    "* Each row has a True under the corresponding color and False for the rest. You can change the dtype to int so that it returns 1 and 0 for each column, for example:\n",
    "  ```python\n",
    "  dummy_df = pd.get_dummies(data['color'], prefix='color', dtype=int)\n",
    "  ```\n",
    "* The prefix='color' argument ensures that the dummy columns are prefixed with the word color.\n",
    "\n",
    "This approach is widely used to convert categorical variables into a format suitable for machine learning models. To learn more about pd.get_dummies() and its usage, refer to the [pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "for var in cat_vars:\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies(data[var], prefix=var, dtype = int) # by default, it returns True or False\n",
    "    data1=data.join(cat_list)\n",
    "    \n",
    "    \n",
    "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "data_vars=data1.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in cat_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final data columns will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=data1[to_keep]\n",
    "data_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. **Random Over-sampling the minority class**  \n",
    "In this section, we will learn about over-sampling, which is the process of randomly duplicating observations from the minority class to achieve a balanced dataset.\n",
    "\n",
    "The most common approach to over-sampling is to resample with replacement. Here's how to proceed:\n",
    "\n",
    "- Import the necessary resampling module from Scikit-Learn.\n",
    "- Split the data into training and testing sets using train_test_split.\n",
    "- Separate the majority and minority classes in the training data.\n",
    "- Upsample the minority class by randomly duplicating its samples.\n",
    "- Combine the upsampled minority class with the majority class to create a balanced dataset.\n",
    "- Split the data back into features (X_train) and target (y_train).\n",
    "- Applied `StandardScaler` to standardize both training and testing features to get `X_train_scaled` and `X_test_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import resample module and Scaler \n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Split data into X and y\n",
    "X = ...\n",
    "y = ...\n",
    "\n",
    "# Split data into training and testing sets using train_test_split\n",
    "X_train_bef, X_test, y_train_bef, y_test = train_test_split(X, y, test_size=0.3, random_state=100) \n",
    "\n",
    "# Combine X_train and y_train\n",
    "train_data = pd.concat([X_train_bef, y_train_bef], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Separate majority and minority classes\n",
    "# majority: train data with y == 0, minority: train data with y == 1\n",
    "majority = ...\n",
    "minority = ...\n",
    "\n",
    "# Upsample minority class\n",
    "minority_upsampled = resample(minority,\n",
    "                              replace=True,   # Sample with replacement\n",
    "                              n_samples=len(majority),  # Match majority class size\n",
    "                              random_state=0)  # Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Combine majority and upsampled minority\n",
    "upsampled_data = ...\n",
    "\n",
    "# Split back into features and target\n",
    "X_train = ...\n",
    "y_train = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Scale features in X_train and X_test\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = ...\n",
    "X_test_scaled = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You may have noticed that the over-sampling was performed only on the training data. This is important because by over-sampling only the training set, we ensure that no information from the test data is used to create synthetic observations. This prevents any potential data leakage, where information from the test set might influence the model training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Random over-sampling is a straightforward yet powerful technique for addressing class imbalance. However, it can sometimes lead to overfitting, as the model may memorize duplicated samples rather than learning to generalize effectively. To mitigate this, consider combining random over-sampling with more sophisticated approaches like SMOTE (Synthetic Minority Over-sampling Technique), which generates synthetic samples instead of duplicating existing ones. you can explore a variety of techniques and strategies in future projects when dealing with imbalanced data. Below are some popular methods for addressing class imbalance:\n",
    "\n",
    "### Alternative Resampling Techniques:\n",
    "\n",
    "**Under-sampling the Majority Class:** This involves reducing the number of samples in the majority class to match the size of the minority class. While it can balance the dataset, it risks discarding potentially valuable information from the majority class.\n",
    "\n",
    "**SMOTE (Synthetic Minority Over-sampling Technique):** Unlike random over-sampling, SMOTE creates synthetic samples for the minority class by interpolating between existing samples. This helps to reduce the risk of overfitting.\n",
    "\n",
    "**ADASYN (Adaptive Synthetic Sampling):** Similar to SMOTE, ADASYN focuses on generating more synthetic samples in regions where the minority class is under-represented, improving the classifier's performance on difficult-to-learn samples.\n",
    "\n",
    "**Cluster-based Over-sampling:** Groups data into clusters before over-sampling the minority class within each cluster, ensuring better representation and diversity of the synthetic samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. **Logistic Regression Model Fitting**\n",
    "In this section, we will fit a logistic regression model to the training data and evaluate its performance on the test data. \n",
    "\n",
    "### Instructions\n",
    "- Instantiate the logistic regression model using `LogisticRegression()`.\n",
    "- Train the model using the `fit` method on the training data (`X_train_scaled` and `y_train`).\n",
    "- Make predictions on the test data (`X_test_scaled`) using the `predict` method.\n",
    "- Calculate the model's accuracy on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Instantiate the logistic regression model\n",
    "logreg = ...\n",
    "\n",
    "# Fit the model to the training data\n",
    "...\n",
    "\n",
    "# Make predictions on the test and display the accuracy\n",
    "y_pred = ...\n",
    "\n",
    "# Calculate and display the accuracy\n",
    "accuracy = ...\n",
    "print(f'Accuracy of logistic regression classifier on test set: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Grid Searching for selecting hyperparameters**\n",
    "\n",
    "Our initial logistic regression model achieved an accuracy of approximately 85%, which was a promising start. To further explore potential improvements, we will conduct a grid search to fine-tune the hyperparameters of the model.\n",
    "\n",
    "A **grid search** systematically tests combinations of hyperparameter values to determine the best-performing model. In this case, we'll focus on two hyperparameters of the logistic regression model:\n",
    "1. **Penalty**: Regularization technique used to avoid overfitting.\n",
    "2. **C**: Inverse of regularization strength (smaller values specify stronger regularization).\n",
    "\n",
    "### **Instructions**\n",
    "- Combine the hyperparameter lists of `penalty` and `C` into a dictionary using `dict()`, with keys as hyperparameter names and values as the corresponding lists.\n",
    "- Instantiate `GridSearchCV` with the attributes set as `estimator = lgr`, `param_grid = param_grid` and store this instance in the `grid_search` variable\n",
    "- Fit `GridSearchCV` with the training data (`X_train_scaled`, `y_train`).\n",
    "- Access the best hyperparameter combination using `.best_params_`, the best score using `.best_score_`, and the best model using `.best_estimator_`\n",
    "- Evaluate the final model on the test set using `confusion_matrix` and `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace ... with your code\n",
    "# Define hyperparameter grid\n",
    "penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "C = [0.01, 0.1, 1, 10]\n",
    "\n",
    "# Combine the lists into a dictionary\n",
    "hyperparameters = ...\n",
    "\n",
    "# Create logistic regression model\n",
    "lgr = ...\n",
    "\n",
    "# Use GridSearch\n",
    "grid_search = ...\n",
    "\n",
    "# Fit the model\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Best parameters, score (accuracy by default) and best model\n",
    "best_params = ...\n",
    "best_score = ...\n",
    "best_model = ...\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Best Model:\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the final model\n",
    "y_pred = ...\n",
    "conf_matrix = ...\n",
    "classification_rpt = ...\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)  \n",
    "print(\"Classification Report:\\n\", classification_rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicated that the optimized hyperparameters did not yield a significant improvement in performance. This outcome suggests that the default hyperparameters for logistic regression were already well-suited for the given dataset. Alternatively, it could indicate that other factors, such as the data quality, feature selection, or the nature of the problem, might play a more critical role in improving the model's performance.\n",
    "\n",
    "This exercise reinforces the importance of testing and validating assumptions during the model optimization process. While hyperparameter tuning is a valuable tool, it is not always guaranteed to lead to better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Confusion Matrix and Classification Metrics\n",
    "\n",
    "A **confusion matrix** is a performance evaluation tool for classification models. It provides detailed insights into how well a classification algorithm performs, breaking down predictions into four categories:\n",
    "\n",
    "|                     | **Predicted Positive** | **Predicted Negative** |\n",
    "|---------------------|-------------------------|-------------------------|\n",
    "| **Actual Positive** | True Positive (TP)      | False Negative (FN)     |\n",
    "| **Actual Negative** | False Positive (FP)     | True Negative (TN)      |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Terms in the Confusion Matrix\n",
    "1. **True Positive (TP)**: The model correctly predicted a positive outcome.\n",
    "2. **True Negative (TN)**: The model correctly predicted a negative outcome.\n",
    "3. **False Positive (FP)**: The model predicted positive when it is actually negative (Type I error).\n",
    "4. **False Negative (FN)**: The model predicted negative when it is actually positive (Type II error).\n",
    "\n",
    "---\n",
    "\n",
    "### How to Calculate and Interpret Metrics\n",
    "Using the values from the confusion matrix, you can derive important classification metrics:\n",
    "\n",
    "#### 1. **Accuracy** \n",
    "   - **Formula**:  \n",
    "     \n",
    "     $${Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "     \n",
    "   - **Interpretation**: The percentage of all predictions (positive and negative) that are correct.\n",
    "   - **Limitation**: Can be misleading for imbalanced datasets (e.g., when one class dominates).\n",
    "\n",
    "#### 2. Precision (Positive Predictive Value)  \n",
    "   - **Formula**:  \n",
    "     \n",
    "     $${Precision} = \\frac{TP}{TP + FP}$$\n",
    "    \n",
    "   - **Interpretation**: Of all instances predicted as positive, how many are actually positive.\n",
    "   - **Importance**: High precision reduces false positives.\n",
    "\n",
    "#### 3. Recall (Sensitivity or True Positive Rate)  \n",
    "   - **Formula**:  \n",
    "   \n",
    "     $${Recall} = \\frac{TP}{TP + FN}$$\n",
    "  \n",
    "   - **Interpretation**: Of all actual positives, how many were correctly predicted.\n",
    "   - **Importance**: High recall reduces false negatives.\n",
    "\n",
    "#### 4. F1-Score (Harmonic Mean of Precision and Recall) \n",
    "   - **Formula**:  \n",
    "    \n",
    "     $${F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "    \n",
    "   - **Interpretation**: A balanced metric that considers both precision and recall. Useful for imbalanced datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluating Model Performance\n",
    "- **Single Accuracy**:\n",
    "  - Simpler but less informative for imbalanced datasets.\n",
    "  - Example: If 90% of data belongs to one class, a model predicting only that class achieves 90% accuracy without identifying any minority-class samples.\n",
    "\n",
    "- **Confusion Matrix**:\n",
    "  - Provides a detailed breakdown of correct and incorrect predictions.\n",
    "  - Helps calculate additional metrics like precision, recall, and F1-score to better evaluate model performance in complex scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### Example of Imbalanced Dataset\n",
    "- Dataset: 100 samples, 95 negatives, 5 positives.\n",
    "- Model predicts all negatives:\n",
    "  - Accuracy: 95% (good score).\n",
    "  - Recall: 0% for the positive class (poor performance).\n",
    "  \n",
    "Using only accuracy hides the model's inability to predict the minority class.\n",
    "\n",
    "---\n",
    "\n",
    "A **confusion matrix** and derived metrics like **precision**, **recall**, and **F1-score** provide a more comprehensive view of model performance than accuracy alone, especially in cases with imbalanced datasets or when certain types of errors (e.g., false positives or false negatives) are more costly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "task1": {
     "name": "task1",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert data.shape[0] == 41188, 'Dataset should have 41188 rows. Please check if you loaded the correct dataset.'\n>>> assert data.shape[1] == 21, 'Dataset should have 21 columns. Please check if you loaded the correct dataset.'\n>>> assert head_data.shape[0] == 5, \"The 'head_data' should return exactly 5 rows. Ensure you are using the 'head()' function correctly.\"\n>>> assert data_description.equals(data.describe()), \"The function used to get summary of statistics is not correct. Ensure you use the 'describe()' method.\"\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task2": {
     "name": "task2",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(missing_values, pd.Series), 'The output of `isnull().sum()` should be a pandas Series.'\n>>> assert missing_values.sum() == 0, 'Missing values count should be non-negative.'\n>>> assert len(data_shape) == 2, 'The shape should have two dimensions (rows, columns).'\n>>> assert data_shape[0] == 41188, 'The DataFrame should have at least one row.'\n>>> assert data_shape[1] == 21, 'The DataFrame should have at least one column.'\n>>> assert len(education_categories) == 8, 'The `education` column should contain 8 unique categories.'\n>>> assert list(education_categories) == ['basic.4y', 'unknown', 'university.degree', 'high.school', 'basic.9y', 'professional.course', 'basic.6y', 'illiterate']\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task3": {
     "name": "task3",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert y_value_counts.sum() == 41188, 'The sum of value counts should equal the total number of rows.'\n>>> assert y_value_counts[0] == 36548, 'The number of 0 class is not correct.'\n>>> assert y_value_counts[1] == 4640, 'The number of 1 class is not correct.'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        },
        {
         "code": ">>> assert count_no_sub == 36548, 'Count of non-subscriptions is wrong.'\n>>> assert count_sub == 4640, 'Count of subscriptions is wrong.'\n>>> assert count_no_sub + count_sub == 41188, 'The sum of subscriptions and non-subscriptions should equal the total number of rows.'\n>>> assert pct_of_no_sub == 36548 / 41188, 'The value of pct_of_no_sub is wrong'\n>>> assert pct_of_sub == 4640 / 41188, 'The value of pct_of_sub is wrong'\n>>> assert np.isclose(pct_of_no_sub + pct_of_sub, 1), 'The sum of percentages should equal 100%.'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        },
        {
         "code": ">>> expected_grouped_means = data.groupby('y').mean(numeric_only=True)\n>>> assert grouped_means.equals(expected_grouped_means), 'The output of `groupby().mean()` is not correct'\n>>> assert isinstance(grouped_means, pd.DataFrame), 'The output of `groupby().mean()` should be a pandas DataFrame.'\n>>> assert 'y' not in grouped_means.columns, \"The grouped DataFrame should not contain the 'y' column.\"\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task5": {
     "name": "task5",
     "points": 30,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X.shape[0] == 41188, 'The number of rows in X should match the number of rows in data_final.'\n>>> assert y.shape[0] == 41188, 'The number of rows in y should match the number of rows in data_final.'\n>>> assert 'y' not in X.columns, \"'y' column should not be present in X.\"\n",
         "hidden": false,
         "locked": false,
         "points": 5
        },
        {
         "code": ">>> assert len(majority) == 25622, 'The majority class is empty.'\n>>> assert len(minority) == 3209, 'The minority class is empty.'\n>>> assert majority.shape[0] + minority.shape[0] == train_data.shape[0], 'The majority and minority classes do not sum up to the training data size.'\n>>> assert minority_upsampled.shape[0] == majority.shape[0], 'The number of upsampled minority class samples is not equal to the majority class.'\n>>> assert minority_upsampled.shape[0] > minority.shape[0], 'The minority class was not upsampled properly.'\n>>> assert majority.equals(train_data[train_data['y'] == 0]), 'wrong majority'\n>>> assert minority.equals(train_data[train_data['y'] == 1]), 'wrong minority'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        },
        {
         "code": ">>> assert upsampled_data.shape[0] == majority.shape[0] + minority_upsampled.shape[0], 'The concatenated data has incorrect size.'\n>>> assert 'y' in upsampled_data.columns, \"The 'y' column is missing in the upsampled data.\"\n>>> assert 'y' not in X_train.columns, \"'y' should not be present in X_train.\"\n>>> assert y_train.shape[0] == upsampled_data.shape[0], \"The size of y_train doesn't match the number of rows in the upsampled data.\"\n>>> assert len(y_train[y_train == 0]) == len(y_train[y_train == 1]), 'The class distribution after upsampling is not balanced.'\n>>> assert set(y_train).issubset({0, 1}), 'The y_train variable contains values outside the expected 0 and 1 classes.'\n",
         "hidden": false,
         "locked": false,
         "points": 10
        },
        {
         "code": ">>> assert X_train_scaled.shape == X_train.shape, 'X_train_scaled should have the same shape as X_train'\n>>> assert X_test_scaled.shape == X_test.shape, 'X_test_scaled should have the same shape as X_test'\n>>> assert np.allclose(X_train_scaled.mean(axis=0), 0, atol=1e-07), 'Mean of scaled features in X_train_scaled should be close to 0'\n>>> assert np.allclose(X_train_scaled.std(axis=0), 1, atol=1e-07), 'Standard deviation of scaled features in X_train_scaled should be close to 1'\n>>> assert np.allclose((X_test - scaler.mean_) / scaler.scale_, X_test_scaled, atol=1e-07), 'X_test_scaled should be consistent with the scaling applied during fit on X_train'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task6": {
     "name": "task6",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert hasattr(logreg, 'coef_'), 'The logistic regression model was not trained properly.'\n>>> assert round(accuracy, 2) == 0.85, 'The accuracy value is not correct.'\n>>> assert len(y_pred) == len(y_test), 'The number of predictions should match the number of test samples.'\n",
         "hidden": false,
         "locked": false,
         "points": 20
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task7": {
     "name": "task7",
     "points": 30,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert hyperparameters == {'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'C': [0.01, 0.1, 1, 10]}, 'Hyperparameter dictionary is incorrect.'\n>>> assert isinstance(lgr, LogisticRegression), 'Logistic Regression model not instantiated correctly.'\n>>> assert isinstance(grid_search, GridSearchCV), 'GridSearchCV is not instantiated correctly.'\n>>> assert grid_search.param_grid == hyperparameters, 'Parameter grid is incorrect in GridSearchCV.'\n",
         "hidden": false,
         "locked": false,
         "points": 10
        },
        {
         "code": ">>> assert grid_search.best_params_ == best_params, 'Best parameters do not match GridSearchCV output.'\n>>> assert grid_search.best_score_ == best_score, 'Best score does not match GridSearchCV output.'\n>>> assert grid_search.best_estimator_ == best_model, 'Best model does not match GridSearchCV output.'\n",
         "hidden": false,
         "locked": false,
         "points": 10
        },
        {
         "code": ">>> assert y_pred.shape[0] == y_test.shape[0], 'Predictions shape does not match test data shape.'\n>>> assert conf_matrix[0][0] == 9296 or conf_matrix[0][1] == 1630 or conf_matrix[1][0] == 209 or (conf_matrix[1][1] == 1222), 'The values in confusion matrix are not correct.'\n",
         "hidden": false,
         "locked": false,
         "points": 10
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

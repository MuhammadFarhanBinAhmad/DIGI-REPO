{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea907d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Otter Grader is an autograder that is designed to grade \n",
    "# Python and R code. We choose it to grade your assignments. \n",
    "# Otter also supports in-notebook checks so that you can \n",
    "# check the progress when working through assignments.\n",
    "# Use the `grader.check()` function in the cells to get feedback on your solution.\n",
    "\n",
    "# Execute this cell for the first time to install the otter library\n",
    "!pip install otter-grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02edefcd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"assignment1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a7201e",
   "metadata": {},
   "source": [
    "# CS385/CSD3185/CSD3186: Assignment 1\n",
    "\n",
    "## Topics Covered\n",
    "- Linear Regression\n",
    "- Gradient Descent Algorithm\n",
    "- Mean Squared Error (MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f164c746",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d9947a",
   "metadata": {},
   "source": [
    "1. Apply gradient descent algorithm to predict the housing prices in Boston city.  \n",
    "2. Get familiarized on determining values of hyperparameters and evaluating the performance of a machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac97acd",
   "metadata": {},
   "source": [
    "## Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd7f70",
   "metadata": {},
   "source": [
    "Your submission for this assignment should be __ONE__ file - a zip file generated by the `grader.export(_)` function down below under 'Submission'. This function will auto create the zip file which contains this particular completed notebook file for you.  \n",
    "\n",
    "Subsequently, rename your zip file like this: __coursecode_A1_your_full_name.zip__  \n",
    "Eg. CS385_A1_john_doe.zip  \n",
    "\n",
    "To complete this assignment, you should follow instructions in Section Tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1578c",
   "metadata": {},
   "source": [
    "## IMPORTANT! READ THIS BEFORE STARTING...\n",
    "- DO NOT delete existing cells, but you can add more cells in between.\n",
    "- DO NOT modify the content of the existing cells unless otherwise stated.\n",
    "- Run the cell with `grader.check(_)` to check your solutions whenever you have completed each tasks.\n",
    "- Follow the file naming convention for the zip file as spelled out above strictly.\n",
    "- DO NOT rename this notebook file. It shall be 'assignment1.ipynb'. \n",
    "\n",
    "Please adhere strictly to the instructions as stated above as failure to do so might result in deduction of marks by the autograder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881eaaef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc21da5",
   "metadata": {},
   "source": [
    "Your tasks begins here!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc41552",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57231de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ca47d",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabdd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT modify the code below (ensure dataset in same folder as this notebook)\n",
    "df = pd.read_csv('Boston_housing_price.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e3af3",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df.drop(\"MEDV\", axis=1).values  # Convert to numpy array for slicing\n",
    "y = df[\"MEDV\"].values  # Ensure y is a column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72855e1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    " __Task 1__ (5 marks)  \n",
    " Split your data into train and test set with train set holding 404 rows and test set with 102 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de7b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset into Train (404 rows) and Test (102 rows) sets\n",
    "# Replace ... with your code\n",
    "X_train = ...\n",
    "y_train = ...\n",
    "X_test = ...\n",
    "y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d1a27",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Validate your train and test set.  \n",
    "`X_train.shape, X_test.shape` should print `(404, 13) (102, 13)`  \n",
    "`y_train.shape, y_test.shape` should print `(404,) (102,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c0c42a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8440d3e7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7de248",
   "metadata": {},
   "source": [
    "## Normalization of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1726962",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Task 2__ (15 marks)    \n",
    "Create a function `z_score_norm` that uses Z-score normalization for features scaling.  \n",
    "Use numpy vectorization operation instead of using `for` loop to achieve your goal. (Hint: `np.mean()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4787c2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def z_score_norm(X) :\n",
    "    \"\"\"\n",
    "    Normalize dataset using Z-Score normalization.\n",
    "    Inputs: X - numpy.ndarray, the dataset for normalization\n",
    "    Outputs: (X_norm, (mean, std)) - tuple, the normalized dataset and mean/std for each feature\n",
    "    \"\"\"\n",
    "    # replace ... with your code\n",
    "    mean = ...\n",
    "    std = ...\n",
    "    X_norm = ...\n",
    "    return X_norm, (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57e560",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X_train_norm, z_score_vals = z_score_norm(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b93426",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Validate your normalized data. Use `print(np.mean(X_train_norm, axis=0))` and verify if the output is similar as below:  \n",
    "[-5.27630744e-17 -5.27630744e-17  2.02258452e-16  3.51753830e-17\n",
    " -2.63815372e-16  1.93464606e-16 -5.27630744e-17  2.02258452e-16\n",
    " -3.51753830e-17 -1.93464606e-16  1.24872610e-15 -1.35425224e-15\n",
    "  1.05526149e-16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22f1f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(np.mean(X_train_norm, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82afbc33",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bbb794",
   "metadata": {},
   "source": [
    "Alternatively, we can use the StandardScaler class from scikit-learn to normalize the dataset and verify that the results are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_norm_sk = StandardScaler().fit_transform(X_train)\n",
    "print(np.mean(X_train_norm_sk, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383b18c",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE) function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f7522",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Task 3__ (15 marks)    \n",
    "Create a function to calculate the Mean Squared Error (MSE) for multiple features. The function should take the input features, target values, bias, and weights as inputs, and return the MSE as float.  \n",
    "*Note: This function will be used in the `train` function later.*  \n",
    "*Note: Use numpy vectorization method instead of for loop.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db7f23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "def loss_MSE(X, Y, b, W) -> float:\n",
    "    \"\"\"\n",
    "    Generalized MSE calculation for multiple features.\n",
    "    Inputs: X - numpy.ndarray, the input feature values\n",
    "            Y - numpy.ndarray, the true output values\n",
    "            b - float/int, bias\n",
    "            W - numpy.ndarray, weights for features\n",
    "    Outputs: MSE - float\n",
    "    \"\"\"\n",
    "    # replace ... with your code\n",
    "    ...\n",
    "    return float(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1846b39e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Validate your MSE function by executing the following statement, the output should be:  \n",
    "670.0209405940593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7959023",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "loss_MSE(X_train, y_train, 0, np.zeros((X_train.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df02b1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf11223",
   "metadata": {},
   "source": [
    "## Bias and weight computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b021967d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Task 4__ (25 marks)  \n",
    "Create a function to update the bias and weights. The function should return the updated bias and weights as a tuple.  \n",
    "*Note: This function will be used in the `train` function later.*  \n",
    "*Note: Use numpy vectorization method instead of for loop.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db48495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update Bias and Weights\n",
    "def update_bias_weights(X, Y, b, W, learning_rate):\n",
    "    \"\"\"\n",
    "    Update bias and weights for multiple features using Gradient Descent.\n",
    "    Inputs: X - numpy.ndarray, the input feature values\n",
    "            Y - numpy.ndarray, the true output values\n",
    "            b - float/int, bias\n",
    "            W - numpy.ndarray, weights for features\n",
    "            learning_rate - float, the learning rate\n",
    "    Outputs: (b, W) - tuple, the updated bias and weights\n",
    "    \"\"\"\n",
    "    # replace ... with your code\n",
    "    ...\n",
    "    return b, W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29226027",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Validate your bias and weight function by executing the following statement, the output should be:  \n",
    "4.835148514851486  \n",
    "[5.83764037e+00 8.34692079e+01 4.12637550e+01 4.92772277e-01\n",
    " 2.50331342e+00 3.16321551e+01 2.95818871e+02 2.06984080e+01\n",
    " 3.00719307e+01 1.62410193e+03 8.53398366e+01 1.84758496e+03\n",
    " 4.59696307e+01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4bd87",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "b, W = update_bias_weights(X_train, y_train, 0, np.zeros((X_train.shape[1])), 0.1)\n",
    "print(b)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a154c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc85ae",
   "metadata": {},
   "source": [
    "### The training and optimal learning rate function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c46e97",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Task 5__ (40 marks)   \n",
    "For this task, you are required to create two functions as detailed below and will be evaluated together by producing the MSE for the best learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259a6e2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Create a function to train the model. The function will iterate over the training data for a specified number of iterations, updating the bias and weights at each step. The function will return the loss history and the final bias and weights.  \n",
    "*Note: The loss history is a list of the mean squared error (MSE) after each iteration.*  \n",
    "*Note: The function will utilize the `loss_MSE` and `update_bias_weights` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8b1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Model\n",
    "def train(X, Y, b, W, learning_rate, learning_iterations):\n",
    "    \"\"\"\n",
    "    Train a linear regression model for multiple features.\n",
    "    Inputs: X - numpy.ndarray, the input feature values\n",
    "            Y - numpy.ndarray, the true output values\n",
    "            b - float/int, bias\n",
    "            W - numpy.ndarray, weights for features\n",
    "            learning_rate - float, the learning rate\n",
    "            learning_iterations - int, the number of training iterations\n",
    "    Outputs: (loss_history, b, W) - tuple, the loss history and the final bias and weights\n",
    "    \"\"\"\n",
    "    # replace ... with your code\n",
    "    ...\n",
    "    return loss_history, b, W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f28b6d3",
   "metadata": {},
   "source": [
    "Create a function to find the optimal learning rate for training the model. The learning rate is a hyperparameter of gradient descent algorithm. Choosing the learning rate is challenging. A too small value may result in a long training process, whereas a too large value may result in learning divergence.  \n",
    "*Note: This function uses the `train` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8408bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select optimal learning rate\n",
    "def optimal_learning_rate(X, Y, b, W, learning_rates, learning_iterations):\n",
    "    \"\"\"\n",
    "    Select the best learning rate based on the final MSE.\n",
    "    Inputs:\n",
    "        X - numpy.ndarray, the input feature values\n",
    "        Y - numpy.ndarray, the true output values\n",
    "        b - float/int, initial bias\n",
    "        W - numpy.ndarray, initial weights for features\n",
    "        learning_rates - list, a list of learning rates to evaluate\n",
    "        learning_iterations - int, the number of training iterations for each learning rate\n",
    "    Outputs:\n",
    "        best_lr - float, the learning rate with the lowest final MSE\n",
    "        best_loss - float, the final MSE for the best learning rate\n",
    "        results - dict, details of MSE for all learning rates\n",
    "    \"\"\"\n",
    "    # replace ... with your code\n",
    "    ...\n",
    "    return best_lr, best_loss, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5581c7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Finally, time to piece all of work or functions completed earlier. Execute the cell below to test if your functions work properly.  \n",
    "Use the following learning rates: [0.001, 0,1]. For each learning rate, train the model for 10000 iterations and record the final loss.  \n",
    "If all works, the output should look like:  \n",
    "<pre>\n",
    "Results for all learning rates:\n",
    "Learning rate: 0.001, Final MSE: 22.80830\n",
    "Learning rate: 0.1, Final MSE: 22.77838\n",
    "\n",
    "Best learning rate: 0.1 with Final MSE: 22.77838\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b1ce3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize bias and weights\n",
    "initial_b = 0\n",
    "initial_W = np.zeros((X_train.shape[1]))\n",
    "\n",
    "# Define learning rates to test\n",
    "learning_rates = [0.001, 0.1]\n",
    "\n",
    "# Number of iterations\n",
    "learning_iterations = 10000\n",
    "\n",
    "# Find the best learning rate\n",
    "best_lr, best_loss, all_results = optimal_learning_rate(X_train_norm, y_train, initial_b, initial_W, learning_rates, learning_iterations)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nResults for all learning rates:\")\n",
    "for lr, loss in all_results.items():\n",
    "    print(f\"Learning rate: {lr}, Final MSE: {loss:.5f}\")\n",
    "\n",
    "print(f\"\\nBest learning rate: {best_lr} with Final MSE: {best_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1b48d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f2db2",
   "metadata": {},
   "source": [
    "Plot the loss history for the best learning rate. The loss history should show the MSE decreasing over the training iterations (plot the first 100 iterations). (Hint: use `train` to obtain the loss history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d0ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# complete the code below\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1afd8",
   "metadata": {},
   "source": [
    "## Predict on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d15fe",
   "metadata": {},
   "source": [
    "  Perform Z-Score normalization on the test set using the mean and standard deviation values from the training set. Subsequently, evaluate the model on the test set using the final bias and weights from the best learning rate. What is the MSE on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3970827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean and std from z_score_vals\n",
    "means, stds = z_score_vals\n",
    "\n",
    "# complete the code below\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb600a3e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff80cbe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## <a id='sub-id'></a> Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db544ed4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d2741",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "task1": {
     "name": "task1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_train.shape == (404, 13), 'X_train.shape is incorrect'\n>>> assert X_test.shape == (102, 13), 'X_test.shape is incorrect'\n>>> assert y_train.shape == (404,), 'y_train.shape is incorrect'\n>>> assert y_test.shape == (102,), 'y_test.shape is incorrect'\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task2": {
     "name": "task2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> print(np.mean(X_train_norm, axis=0))\n[-5.27630744e-17 -5.27630744e-17  2.02258452e-16  3.51753830e-17\n -2.63815372e-16  1.93464606e-16 -5.27630744e-17  2.02258452e-16\n -3.51753830e-17 -1.93464606e-16  1.24872610e-15 -1.35425224e-15\n  1.05526149e-16]\n",
         "hidden": false,
         "locked": false,
         "points": 15
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task3": {
     "name": "task3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> loss = loss_MSE(X_train, y_train, 0, np.zeros(X_train.shape[1]))\n>>> assert np.isclose(round(loss, 2), 670.02), 'loss_MSE is incorrect'\n",
         "hidden": false,
         "locked": false,
         "points": 15
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task4": {
     "name": "task4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import math\n>>> assert math.isclose(b, 4.835148514851486, rel_tol=1e-09, abs_tol=0.0001), 'b is incorrect'\n",
         "hidden": false,
         "locked": false,
         "points": 10
        },
        {
         "code": ">>> print(W)\n[5.83764037e+00 8.34692079e+01 4.12637550e+01 4.92772277e-01\n 2.50331342e+00 3.16321551e+01 2.95818871e+02 2.06984080e+01\n 3.00719307e+01 1.62410193e+03 8.53398366e+01 1.84758496e+03\n 4.59696307e+01]\n",
         "hidden": false,
         "locked": false,
         "points": 15
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task5": {
     "name": "task5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import math\n>>> assert best_lr == 0.1, 'best_lr is incorrect'\n>>> assert math.isclose(round(best_loss, 5), 22.77838), 'best_loss is incorrect'\n",
         "hidden": false,
         "locked": false,
         "points": 40
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
